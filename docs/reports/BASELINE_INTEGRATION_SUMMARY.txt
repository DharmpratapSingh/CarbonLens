================================================================================
CLIMATEGPT BASELINE KNOWLEDGE INTEGRATION - QUICK REFERENCE
================================================================================

CORE COMPONENTS
================================================================================

1. BASELINE CONTEXT PROVIDER (src/utils/baseline_context.py)
   - Location: Lines 1-663
   - Class: BaselineContextProvider
   - Loads 4 Knowledge Domains:
     a) Sector Context (8 sectors): transport, power, waste, agriculture, 
        buildings, ind-combustion, ind-processes, fuel-exploitation
     b) Country Context (6 countries): Germany, China, USA, India, France, Japan
     c) Policy Context (4 frameworks): Paris Agreement, Net Zero, Carbon Pricing, IPCC
     d) Persona Frameworks (4 personas): Climate Analyst, Research Scientist,
        Financial Analyst, Student

2. CONTEXT AUGMENTERS (Decorators/Utilities)
   - PolicyContextAugmenter: Adds Paris Agreement alignment context
   - SectorStrategyAugmenter: Provides sector-specific decarbonization strategies
   - EducationalContextAugmenter: Creates relatable analogies and significance explanations

3. LLM RUNNER (src/run_llm.py)
   - Lines: 1-809
   - Orchestrates: Question classification, baseline answer generation, MCP queries,
     baseline enrichment, response summarization
   - Uses singleton caching of BaselineContextProvider

4. MCP SERVER (src/mcp_server_stdio.py)
   - Lines: 1-2800+
   - Handles: Database queries, input validation, quality metadata, suggestions
   - Provides: 8 tools with comprehensive quality information per sector

================================================================================
QUESTION CLASSIFICATION (run_llm.py:236-281)
================================================================================

Classifies questions into 3 types:

BASELINE-only Questions (No MCP query needed)
- Keywords: what is, how does, explain, define, mechanism, greenhouse effect, 
           climate change, paris agreement, net zero
- Treatment: Uses baseline knowledge provider, no database access
- Temperature: 0.2 (consistency)
- Output: 100% conceptual answer with citations

MCP-only Questions (Data without interpretation)
- Keywords: emissions, tonnes, how much, which country, ranking, top, highest,
           change, compare, 2023, 2022, year
- Treatment: Queries database, minimal baseline context
- Temperature: 0.2
- Output: 70% data facts, 30% light interpretation

HYBRID Questions (Both data and interpretation)
- Keywords: Both baseline AND mcp keywords present
- Treatment: Queries database, enriches with baseline context
- Temperature: 0.2
- Output: 40% data facts, 60% interpretation + context

================================================================================
DATA FLOW: HYBRID QUESTION PROCESSING
================================================================================

1. Question: "How did Germany's power emissions change from 2022 to 2023 
             and what does it mean?"

2. Classification: HYBRID (contains "what does it mean" + "2022-2023" + "emissions")

3. Baseline Context Building:
   - Extract elements: sectors=[power], countries=[germany], years=[2022,2023]
   - Build context: sector explanation + country context + trend context
   - Persona framing: Climate Analyst focus areas
   
4. MCP Query Execution:
   - Query: power-country-year for Germany, years 2022-2023
   - MCP Server validates: file_id, country, years, columns
   - Returns: Data rows + quality metadata

5. Response Enrichment:
   - Injects baseline context into summarization prompt
   - Adds sector explanation, country context, trend context
   - Formats: [Sector Context], [Country Context], [Trend Context]

6. LLM Response Generation:
   - System prompt: HYBRID template with 40/60 balance
   - Input: Data + baseline context + persona framing
   - Temperature: 0.2
   - Output: Structured answer with facts, interpretation, insights

================================================================================
GUARDRAILS & VALIDATION
================================================================================

Input Validation (mcp_server_stdio.py:127-141)
- Identifier pattern: ^[a-zA-Z0-9_\-\.]+$ (prevents SQL injection)
- Query complexity limits: max 50 columns, 20 filters, 100 list items
- String length limits: max 500 chars per value

Pre-execution Query Validation (Lines 1500-1558)
1. Temporal coverage: Year in dataset range (2000-2023)?
2. Spatial coverage: City data available for country?
3. Filter ambiguity: Are filters provided? (suggests adding if missing)
4. Column existence: Do requested columns exist in dataset?
5. Auto-suggestions: Generates helpful suggestions if issues detected

Data Quality Configuration (Lines 151-256)
- SECTOR_QUALITY: Quality scores for all 8 sectors
- DATABASE_METRICS: Overall database quality (91.03/100 average)
- Uncertainty bounds: ±8-14% per sector
- Multi-source validation: 95% of records
- External sources: 55+ authoritative sources integrated

Response Balance Constraints (run_llm.py:527-681)
- BASELINE type: 100% conceptual, no data
- MCP type: 70% data, 30% interpretation
- HYBRID type: 40% data, 60% interpretation
- Enforced via system prompts with explicit rules

Persona-Specific Guardrails (run_llm.py:684-703)
- Climate Analyst: "mitigation priorities, policy implications"
- Research Scientist: "methodology, data quality, uncertainty"
- Financial Analyst: "risk signals, concentration, momentum"
- Student: "definitions, analogies, real-world meaning"

Temperature Control
- All responses use temperature=0.2 (low variance, reproducibility)
- Prevents hallucinations and creative interpretation

================================================================================
DATA QUALITY METRICS BY SECTOR
================================================================================

Sector              | Score | Rating              | Uncertainty | Sources | Records
--------------------+-------+---------------------+-------------+---------+--------
Power               | 97.74 | Tier 1 - HIGHEST    | ±8%         | 5       | 161,518
Ind-Combustion      | 96.87 | Tier 1              | ±9%         | 6       | 84,223
Ind-Processes       | 96.40 | Tier 1              | ±9%         | 6       | 91,963
Fuel-Exploitation   | 92.88 | Tier 1              | ±11%        | 5       | 85,083
Transport           | 85.00 | Tier 1              | ±12%        | 5       | 208,677
Buildings           | 85.00 | Tier 1              | ±14%        | 6       | 95,214
Waste               | 88.00 | Tier 1              | ±10%        | 3       | 47,384
Agriculture         | 88.00 | Tier 1              | ±10%        | 2       | 83,446
--------------------+-------+---------------------+-------------+---------+--------
DATABASE AVERAGE    | 91.03 | Tier 1 - All Sectors| 30-73% reduction

Geographic Coverage: 305+ countries, 3,431+ cities
Temporal Coverage: 24 years (2000-2023)
Multi-source Validation: 95% of records (3+ sources per record)
External Sources Integrated: 55+ authoritative sources

================================================================================
RESPONSE STRUCTURE BY QUESTION TYPE
================================================================================

BASELINE-ONLY ANSWER (Lines 284-344)
- Format: Conceptual explanation using baseline knowledge
- Structure: Introduction, explanation, citations, conclusion
- Example: "What is the Paris Agreement?"
  → Background, goals, mechanism, countries' commitments, targets

MCP-ONLY ANSWER (Lines 625-651)
- Format: Data-focused with light interpretation
- Structure: Data statement, source citation, brief interpretation
- Example: "What were Germany's 2023 power emissions?"
  → "227.68 MtCO2, Source: EDGAR v2024. This aligns with renewable expansion trends."

HYBRID ANSWER (Lines 608-624)
- Format: Data + interpretation + strategic insights
- Structure: 
  1. [FACTUAL DATA] Precise numbers with source and dates
  2. [BASELINE INTERPRETATION] Context, policy implications, significance
  3. [STRATEGIC INSIGHTS] Actionable recommendations for persona
- Example: "How did Germany's power emissions change 2022-2023?"
  → Data (22.7% reduction) + Context (Energiewende, Russia-Ukraine)
  → Insights (Paris-aligned, sustain momentum, accelerate coal phase-out)

================================================================================
CACHING & PERFORMANCE OPTIMIZATION
================================================================================

1. Baseline Provider Caching (run_llm.py:20-31)
   - Singleton pattern: _PERSONA_PROVIDER
   - Single initialization of 4 knowledge domains per process
   - Reused across all requests
   - Eliminates repeated knowledge base loading

2. Query Result Caching (mcp_server_stdio.py:1598-1669)
   - LRU cache: 1000 items max
   - TTL: 5 minutes per item
   - Key: MD5 hash of SQL + parameters
   - Thread-safe with locks
   - Tracks hit/miss statistics

3. Connection Pooling (mcp_server_stdio.py:1675+)
   - DuckDB connection pool: 10 base connections
   - Max overflow: 5 additional connections
   - Automatic health checking
   - Thread-safe operations

================================================================================
GRACEFUL DEGRADATION & ERROR HANDLING
================================================================================

1. Baseline Import Handling (run_llm.py:8-18)
   - try/except ImportError catches missing baseline module
   - Sets BASELINE_AVAILABLE flag
   - System continues without baseline if unavailable
   - No hard dependencies

2. Enrichment Failure Handling (run_llm.py:581-605)
   - try/except catches any enrichment errors
   - Silently falls back to data-only answer
   - User still gets valid response

3. MCP Server Error Handling (mcp_server_stdio.py)
   - Pre-execution validation catches issues before query
   - Provides helpful suggestions instead of blank errors
   - Falls back to alternative data (e.g., nearest available year)

================================================================================
TESTING & VALIDATION COVERAGE
================================================================================

Test Files (in /docs/):

1. test_baseline_usage.py (361 lines)
   - Test 1: Question routing classification (BASELINE vs MCP vs HYBRID)
   - Test 2: Hallucination detection (checks for fabricated data)
   - Test 3: MCP vs baseline comparison (data availability)
   - Test 4: Persona-specific context usage (framework validation)

2. direct_baseline_test.py (187 lines)
   - BaselineContextProvider initialization
   - All 4 knowledge domains load
   - Response enrichment mechanism
   - Context augmenters functionality
   - MCP integration verification

3. test_run_llm_baseline.py (148 lines)
   - End-to-end testing of run_llm.py
   - Classification validation for 3 question types
   - Baseline context presence checking
   - MCP data retrieval verification
   - Citation/source validation

================================================================================
INTEGRATION STRENGTHS
================================================================================

1. Separation of Concerns
   - Baseline knowledge in dedicated module
   - MCP server handles data independently
   - LLM runner orchestrates integration

2. Multiple Safety Layers
   - Question classification prevents wrong routing
   - Pre-execution validation catches issues
   - Response balance constraints prevent over-interpretation
   - Uncertainty quantification provided with all data

3. Transparency
   - All responses cite sources (EDGAR v2024)
   - Quality scores included with data
   - Uncertainty bounds quantified
   - Multi-source validation documented
   - Persona-specific guidelines documented

4. Performance
   - Singleton caching for baseline provider
   - Query result caching (LRU, 5min TTL)
   - Connection pooling
   - No per-request overhead for baseline

5. Comprehensive Testing
   - Coverage of all question types
   - Hallucination detection tests
   - Persona-specific validation
   - End-to-end integration tests

================================================================================
KEY FILES & LINE NUMBERS
================================================================================

baseline_context.py
  - BaselineContextProvider class: lines 26-463
  - enrich_response(): lines 45-75
  - _extract_question_elements(): lines 324-354
  - _build_context(): lines 356-395
  - PolicyContextAugmenter: lines 470-501
  - SectorStrategyAugmenter: lines 504-540
  - EducationalContextAugmenter: lines 543-605

run_llm.py
  - get_persona_provider() caching: lines 20-31
  - classify_question(): lines 236-281
  - get_baseline_answer(): lines 284-344
  - exec_tool_call(): lines 421-515
  - summarize() with enrichment: lines 527-681
  - main() orchestration: lines 705-806

mcp_server_stdio.py
  - Input validation: lines 127-141
  - SECTOR_QUALITY config: lines 151-256
  - DATABASE_METRICS: lines 258-283
  - _validate_query_and_suggest(): lines 1500-1558
  - QueryCache class: lines 1598-1669
  - DuckDBConnectionPool class: lines 1675+
  - handle_call_tool(): lines 2567-2605

================================================================================
CONFIGURATION ENVIRONMENT VARIABLES
================================================================================

run_llm.py
- OPENAI_BASE_URL: API endpoint (default: erasmus.ai)
- MODEL: Model identifier (default: /cache/climategpt_8b_test)
- OPENAI_API_KEY: "username:password" format (REQUIRED)
- PORT: MCP server port (default: 8010)

mcp_server_stdio.py
- MCP_MANIFEST_PATH: Manifest file path (default: data/curated-2/manifest_mcp_duckdb.json)
- LOG_LEVEL: Logging level (default: INFO)
- LOG_FORMAT: json or text (default: json)
- LOG_FILE: Optional log file path
- ASSIST_DEFAULT: Enable assist mode (default: true)
- PROXY_DEFAULT: Enable proxy mode (default: false)
- PROXY_MAX_K: Max proxy neighbors (default: 3)
- PROXY_RADIUS_KM: Proxy search radius (default: 150)

================================================================================
END OF REFERENCE
================================================================================
